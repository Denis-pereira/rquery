---
title: "rquery"
output: github_document
date: "2017-12-07"
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

`rquery` is a experiment/demonstration of a simplified sequenced query language based on [Codd's relational algebra](https://en.wikipedia.org/wiki/Relational_algebra) and not currently recommended for non-experimental use.  The goal of this experiment is to see if `SQL` would be more fun if it had a sequential data-flow or pipe notation.

`rquery` is not for production use, but can be an excellent advanced `SQL`
training tool (it shows how some very deep `SQL` by composing `rquery` operators).  Currently `rquery` is biased towards `PostgeSQL` `SQL`.

There are many prior relational algebra inspired specialized query languages.  Just a few include:

  * [Alpha](https://en.wikipedia.org/wiki/Alpha_(programming_language))
  * [QUEL](https://en.wikipedia.org/wiki/QUEL_query_languages)
  * [Tutorial D](https://en.wikipedia.org/wiki/D_(data_language_specification)#Tutorial_D)
  * [`LINQ`](https://msdn.microsoft.com/en-us/library/bb308959.aspx)
  * [`SQL`](https://en.wikipedia.org/wiki/SQL)
  * [`dplyr`](http://dplyr.tidyverse.org)
 

`rquery` itself is a thin translation to `SQL` layer, but we are trying to put the Codd relational operators front and center (using the original naming, and back-porting `SQL` progress such as window functions to the appropriate relational operator).  `rquery` differs from `dplyr` in that `rquery` is trying to stay near the Codd relational operators (in particular grouping is a transient state inside the `rquery::extend()` operator, not a durable user visible annotation as with `dplyr::group_by()`).

The primary relational operators are:

  * `extend()`.  Extend adds derived columns to a relation table.  With a sufficiently powerful `SQL` provider this includes ordered and partitioned window functions.  This sort of operator can eventually encompass all of a ["grouped ordered apply" methodology](http://www.win-vector.com/blog/2016/12/organize-your-data-manipulation-in-terms-of-grouped-ordered-apply/).
  * `project()`.  Project is usually portrayed as the equivalent to column selection.  In our opinion the original relational nature of the operator is best captured by moving `SQL`'s "`GROUP BY`" aggregation functionality to this operator.
  * `natural_join()`.  This a specialized relational join operator, using all common columns as the equi-join condition.  The next operator to add would definitely be `theta-join` as that adds a lot more expressiveness to the grammar.
  * `theta_join()`.  This is the relational join operator, insisting on distinct columns but allowing an arbitrary matching condition.  The next operator to add would definitely be `theta-join` as that adds a lot more expressiveness to the grammar.
  * `select_rows()`.  This is Codd's relational row selection.  Obviously `select` alone is an over-used and now ambiguous term (it is the "doit" verb in `SQL` and the *column* selector in `dplyr`).
  * `rename_columns()`.  This operator renames sets of columns.
  
The primary non-relational (traditional `SQL`) operators are:

  * `select_columns()`.  This allows choice of columns (central to `SQL`), but is not a relational operator as it can damage row-uniqueness.
  * `order_by()`.  This is a non-relational "user presentation" verb.  Row order is not well-defined in the relational algebra (and also not in most `SQL` implementations).  If used it should be used last in a query (so it is not undone by later operations).
  
The primary missing relational operators are:

  * Union.
  * Direct set difference, anti-join.
  * Division.
  
Primary useful missing operators:

  * Deselect columns.
  * [`seplyr::partition_mutate()`](https://winvector.github.io/seplyr/reference/partition_mutate_qt.html)
  * [`seplyr::if_else_device()`](https://winvector.github.io/seplyr/reference/if_else_device.html)


A great benefit of Codd's relational algebra is it decomposes data transformations into a sequence of operators.  `SQL` loses a lot of the original invariants, and over-specifies how operations are strung together and insisting on a nesting function notation.  `SQL` also realizes some of the Codd concepts as operators, some as expressions, and some as predicates (obscuring the uniformity of the original theory).

A lot of the grace of the Codd theory can be recovered through the usual trick changing function composition notation from `g(f(x))` as `x . f() . g()`.  This is the other inspiration for this experiment: "what if `SQL` were piped?" (wrote composition as a left to right flow, instead of right to left nesting).

The `rquery` operators are passive.  They don't do anything other than collect a specification of the desired calculation.  This data structure can then be printed in a friendly fashion, used to generate `SQL`, and (in principle) be the representational layer for a higher-order optimizer.

As an acid test we generate a query equivalent to the non-trivial `dplyr` pipeline 
demonstrated in [Letâ€™s Have Some Sympathy For The Part-time R User](http://www.win-vector.com/blog/2017/08/lets-have-some-sympathy-for-the-part-time-r-user/).

First we set up the database and the original example data:

```{r ex}
library("rquery")
use_spark <- TRUE

if(use_spark) {
  my_db <- sparklyr::spark_connect(version='2.2.0', 
                                   master = "local")
} else {
  library('RPostgreSQL')
  my_db <- DBI::dbConnect(dbDriver("PostgreSQL"),
                          host = 'localhost',
                          port = 5432,
                          user = 'postgres',
                          password = 'pg')
}


d <- dbi_copy_to(my_db, 'd',
                 data.frame(
                   subjectID = c(1,                   
                                 1,
                                 2,                   
                                 2),
                   surveyCategory = c(
                     'withdrawal behavior',
                     'positive re-framing',
                     'withdrawal behavior',
                     'positive re-framing'
                   ),
                   assessmentTotal = c(5,                 
                                       2,
                                       3,                  
                                       4),
                   stringsAsFactors = FALSE),
                 temporary = TRUE, 
                 overwrite = !use_spark)

print(d)

d %.>%
  to_sql(.) %.>%
  DBI::dbGetQuery(my_db, .) %.>%
  knitr::kable(.)

```

Now we write the calculation in terms of our operators.

```{r calc}
scale <- 0.237

dq <- d %.>%
  extend_nse(.,
             probability :=
               exp(assessmentTotal * scale)/
               sum(exp(assessmentTotal * scale)),
             count := count(1),
             partitionby = 'subjectID') %.>%
  extend_nse(.,
             rank := rank(),
             partitionby = 'subjectID',
             orderby = 'probability')  %.>%
  extend_nse(.,
             isdiagnosis := rank == count,
             diagnosis := surveyCategory) %.>%
  select_rows_nse(., isdiagnosis) %.>%
  select_columns(., c("subjectID", 
                      "diagnosis", 
                      "probability")) %.>%
  order_by(., 'subjectID')
```

The above compares well to [the original `dplyr` pipeline](http://www.win-vector.com/blog/2017/08/lets-have-some-sympathy-for-the-part-time-r-user/).

We then generate our result:

```{r res}
dq %.>%
  to_sql(.) %.>%
  DBI::dbGetQuery(my_db, .) %.>%
  knitr::kable(.)
```

We see we reproduced the result purely in terms of these database operators.

The actual `SQL` query that produces the result is quite involved:

```{r q, comment=''}
cat(to_sql(dq))
```

Part of the plan is: the additional record-keeping in the operator nodes would 
let a very powerful query optimizer work over the flow before it gets translated
to `SQL` (perhaps an extension of or successor to [`seplyr`](https://winvector.github.io/seplyr/), which re-plans over `dplyr::mutate()` expressions).  At the very least restricting to columns later used and folding selects
together would be achievable.  One should have a good chance at optimization as
the representation is fairly high-level, and many of the operators are relational 
(meaning there are known legal transforms a query optimizer can use).  The flow itself
is represented as follows:

```{r pqp, comment=''}
print(dq)
```

We can even pretty-format it:

```{r pq, comment=''}
cat(gsub("%.>%", "%.>%\n   ", 
         format(dq), 
         fixed = TRUE))
```

And that is our experiment.

```{r cleanup}
if(use_spark) {
  sparklyr::spark_disconnect(my_db)
} else {
  DBI::dbDisconnect(my_db)
}
```


Note: `rquery` is only an experimental package. All `rquery` operators should be only used in "zero dependency mode" (never using a value created in the same operator or writing the same value twice) in the sense of [`seplyr::partition_mutate_qt`](https://www.rdocumentation.org/packages/seplyr/versions/0.5.0/topics/partition_mutate_qt); the nodes check this as a pre-condition).  Again, the point was to see how quickly one can get a workable data transform pipeline in terms of Codd-inspired operators. `rquery` can also be used to teach advanced use of `SQL`.

We are also adding custom support for translations [such as `ifelse()`](https://johnmount.github.io/rquery/reference/extend_nse.html).


