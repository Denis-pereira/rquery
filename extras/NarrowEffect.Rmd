---
title: "NarrowEffect"
author: "Win-Vector LLC"
date: "12/18/2017"
output: github_document
---

<!-- NarrowEffect.md is generated from NarrowEffect.Rmd. Please edit that file -->

For some time we have been teaching [`R`](https://journal.r-project.org) users "when working with wide tables on Spark or on databases: narrow to the columns you really want to work with early in your analysis."

This issue arises because wide tables (200 to 1000 columns) are quite common in big-data analytics projects.  Often these are "denormalized marts" that are used to drive many different projects.  For any one project only a small subset of the columns may be relevant in a calculation.

The idea behind the advice is: working with fewer columns makes for quicker queries.


```{r ex, warning=FALSE, message=FALSE, echo=FALSE, include=FALSE}
library("microbenchmark")
suppressPackageStartupMessages(library("dplyr"))
library("rquery")

conf <-  sparklyr::spark_config()
conf$spark.yarn.am.cores <- 4
conf$spark.executor.cores <- 4
conf$spark.executor.memory <- "2G"
conf$spark.yarn.am.memory <- "2G" 
conf$`sparklyr.shell.driver-memory` <- "2G"
conf$`sparklyr.shell.executor-memory` <- "2G"
conf$`spark.yarn.executor.memoryOverhead` <- "2G"
my_db <- sparklyr::spark_connect(version='2.2.0', 
                                 master = "local",
                                 config = conf)

nSubj <- 500000
nIrrelCol <- 100
dL <- data.frame(subjectID = sort(rep(seq_len(nSubj),2)),
                 surveyCategory = c(
                   'withdrawal behavior',
                   'positive re-framing'),
                 stringsAsFactors = FALSE)
dL$assessmentTotal <- sample.int(10, nrow(dL), replace = TRUE)
for(i in seq_len(nIrrelCol)) {
  ni <- paste("irrelevantCol", sprintf("%07g", i), sep = "_")
  dL[[ni]] <- sample(letters, size = nrow(dL), replace = TRUE)
}

d <- rquery::dbi_copy_to(my_db, 'd',
                 dL,
                 temporary = TRUE, 
                 overwrite = FALSE)
dL <- NULL

# copy to Parquet to simulate large external data source
dT <- dplyr::tbl(my_db, d$table_name)
sparklyr::spark_write_parquet(dT, "perf_tmp", mode = 'overwrite')
dplyr::db_drop_table(my_db, d$table_name)
dT <- NULL
d <- NULL

# build new refs
dT <- sparklyr::spark_read_parquet(my_db, 'dparq', "perf_tmp", memory = FALSE)
dR <- dbi_table(my_db, "dparq")
```


Let's set up our experiment.  The data is a larger version of the problem from ["Letâ€™s Have Some Sympathy For The Part-time R User"](http://www.win-vector.com/blog/2017/08/lets-have-some-sympathy-for-the-part-time-r-user/).  We have expanded the number of subjects to `r sprintf("%i",nSubj)` and added `r sprintf("%i",nIrrelCol)` irrelevant columns to the example.  We define a new function that uses `dplyr` and `Sparklyr` to compute the diagnoses.  We vary if the table is first limited to columns of interest and if the results are brought back to `R`.

```{r defexp}
scale <- 0.237
```

```{r defdplyr}
dT %>%
  group_by(subjectID) %>%
  mutate(probability =
           exp(assessmentTotal * scale)/
           sum(exp(assessmentTotal * scale), na.rm = TRUE)) %>%
  arrange(probability, surveyCategory) %>%
  filter(row_number() == n()) %>%
  ungroup() %>%
  rename(diagnosis = surveyCategory) %>%
  select(subjectID, diagnosis, probability) %>%
  arrange(subjectID) %>%
  tally() %>%
  dbplyr::remote_query(.) %>%
  cat

dplyr_run <- function(narrow) {
  dR <- dT
  if(narrow) {
    dR <- dR %>%
      select(subjectID, surveyCategory, assessmentTotal)
  }
  dR <- dR %>%
    group_by(subjectID) %>%
    mutate(probability =
             exp(assessmentTotal * scale)/
             sum(exp(assessmentTotal * scale), na.rm = TRUE)) %>%
    arrange(probability, surveyCategory) %>%
    filter(row_number() == n()) %>%
    ungroup() %>%
    rename(diagnosis = surveyCategory) %>%
    select(subjectID, diagnosis, probability) %>%
    arrange(subjectID) %>%
    tally()
  res <- dR %>% collect() %>% as.data.frame()
  as.numeric(res[[1]][[1]])
}


dplyr_run(narrow=FALSE)

dplyr_run(narrow=TRUE)
```

```{r defrquery}
optree <- dR %.>%
  extend_nse(.,
             probability :=
               exp(assessmentTotal * scale)/
               sum(exp(assessmentTotal * scale)),
             count := count(1),
             partitionby = 'subjectID') %.>%
  extend_nse(.,
             rank := rank(),
             partitionby = 'subjectID',
             orderby = c('probability', 'surveyCategory'))  %.>%
  rename_columns(., 'diagnosis' := 'surveyCategory') %.>%
  select_rows_nse(., rank == count) %.>%
  select_columns(., c('subjectID', 
                      'diagnosis', 
                      'probability')) %.>%
  orderby(., 'subjectID') %.>%
  sql_node(., "n" := "COUNT(1)", orig_columns = FALSE)

cat(to_sql(optree, my_db))

  
rquery_run <- function() {
  optree <- dR %.>%
    extend_nse(.,
               probability :=
                 exp(assessmentTotal * scale)/
                 sum(exp(assessmentTotal * scale)),
               count := count(1),
               partitionby = 'subjectID') %.>%
    extend_nse(.,
               rank := rank(),
               partitionby = 'subjectID',
               orderby = c('probability', 'surveyCategory'))  %.>%
    rename_columns(., 'diagnosis' := 'surveyCategory') %.>%
    select_rows_nse(., rank == count) %.>%
    select_columns(., c('subjectID', 
                        'diagnosis', 
                        'probability')) %.>%
    orderby(., 'subjectID') %.>%
    sql_node(., "n" := "COUNT(1)", orig_columns = FALSE)
  res <- execute(my_db, optree)
  as.numeric(res[[1]][[1]])
}

rquery_run()

```

We can get timings for variations of the function:

```{r time}
library("microbenchmark")

timings <- microbenchmark(dplyr_run(narrow=FALSE), 
                          dplyr_run(narrow=TRUE),
                          rquery_run())
```

And then present the results:

```{r present}
print(timings)

tdf <- as.data.frame(timings)

# order the data
tdf <- tdf %>%
  group_by(., expr) %>%
  mutate(., mtime = median(time)) %>%
  ungroup(.)

tdf$expr <- reorder(tdf$expr, tdf$mtime)
WVPlots::ScatterBoxPlotH(tdf, "time", "expr",  
                         pt_alpha=0.2,
                         title="Execution times in NS")
```

The effect seems to be present, but weaker than last time I measured it.  Though the effect would certainly be there if one inspected an intermediate table.

Of course, narrowing to the exact columns used can be difficult: it can involve inspecting an
arbitrarily long pipeline for column uses.  That is part of why we are developing
a new `R` query generator that automates that procedure: [`rquery`](https://winvector.github.io/rquery/).



```{r cleanup, include=FALSE}
sparklyr::spark_disconnect(my_db)
```

